{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Image classification is the process of taking an image input and outputting a class (like “cat”) or a probability that the input is a particular class (“there’s a 90% probability that this input is a cat”). You can look at a picture and know that you’re looking at a terrible shot of your own face, but how can a computer learn to do that? With a convolutional neural network!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Goals\n",
    "We will implement a neural network architecture involving advanced DNN modules (i.e. convolution layers, RELU, pooling and fully connection layers and etc.)  to distinguish the specific category of an input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Packages\n",
    "Let's first import the necessary packages,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## GPU Device Configuration\n",
    "Then, we set up and configure our computational devices: \n",
    "Whether we use GPU or perform the calculation on CPU.\n",
    "we use the torch.devices() and torch.cude.is_available() functions to configure our computational devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Configuration\n",
    "We then set up hyper parameters that are needed for the model:\n",
    "1. learning rate\n",
    "2. batch size when training\n",
    "3. batch size when testing\n",
    "4. number of epochs\n",
    "5. output directory to save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "train_batch = 128\n",
    "test_batch = 128\n",
    "num_epochs = 20\n",
    "out_dir = \"checkpoints/\"\n",
    "\n",
    "# Creating the directory where the checkpoints (trained model) will be saved\n",
    "if not os.path.exists(\"checkpoints/\"):\n",
    "    os.mkdir(\"checkpoints/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Data Loading\n",
    "### We need to prepare our data:\n",
    "\n",
    "We first import the necessasry libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "###  Image processing\n",
    "Then, we define an image preprocessing object that our dataloader can directly use to preprocess our data.\n",
    "We use the pytorch API to preform the data processing.\n",
    "Note that the testing spilit does not require any transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### We then download and prepare the CIFAR10 dataset with training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "train_loader = data.DataLoader(dataset=train_set, batch_size=train_batch, shuffle=True)\n",
    "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = data.DataLoader(dataset=test_set, batch_size=test_batch, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Network\n",
    "We are going to implement the GoogLeNet CNN Architecture outlined in the following research paper:\n",
    "\n",
    "### https://arxiv.org/abs/1409.4842\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Inception Module with dimension reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_1_x, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_1_x),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_3_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_3_in),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(kernel_3_in, kernel_3_x, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(kernel_3_x),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_5_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_5_in),\n",
    "            nn.ReLU(True),\n",
    "            # 1x1 conv takes 192 turns it into 16, then next conv turns it into 32\n",
    "            nn.Conv2d(kernel_5_in, kernel_5_x, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(kernel_5_x),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(\n",
    "            [self.b1(x), self.b2(x), self.b3(x), self.b4(x)], 1\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### GoogLeNet Module \n",
    "While we do not follow the research paper exactly, we implement a similar architecture based heavily on the Inception Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential( \n",
    "            nn.Conv2d(3, 192, 3, padding = 1), # add padding=1 HERE\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.incept3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.incept3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.incept4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.incept4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.incept4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.incept4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.incept4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.incept5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.incept5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size = 8, stride = 1)\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.incept3a(x)\n",
    "        x = self.incept3b(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.incept4a(x)\n",
    "        x = self.incept4b(x)\n",
    "        x = self.incept4c(x)\n",
    "        x = self.incept4d(x)\n",
    "        x = self.incept4e(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.incept5a(x)\n",
    "        x = self.incept5b(x)\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we create the network and send it to the target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [128, 192, 32, 32]           5,376\n",
      "       BatchNorm2d-2         [128, 192, 32, 32]             384\n",
      "              ReLU-3         [128, 192, 32, 32]               0\n",
      "            Conv2d-4          [128, 64, 32, 32]          12,352\n",
      "       BatchNorm2d-5          [128, 64, 32, 32]             128\n",
      "              ReLU-6          [128, 64, 32, 32]               0\n",
      "            Conv2d-7          [128, 96, 32, 32]          18,528\n",
      "       BatchNorm2d-8          [128, 96, 32, 32]             192\n",
      "              ReLU-9          [128, 96, 32, 32]               0\n",
      "           Conv2d-10         [128, 128, 32, 32]         110,720\n",
      "      BatchNorm2d-11         [128, 128, 32, 32]             256\n",
      "             ReLU-12         [128, 128, 32, 32]               0\n",
      "           Conv2d-13          [128, 16, 32, 32]           3,088\n",
      "      BatchNorm2d-14          [128, 16, 32, 32]              32\n",
      "             ReLU-15          [128, 16, 32, 32]               0\n",
      "           Conv2d-16          [128, 32, 32, 32]          12,832\n",
      "      BatchNorm2d-17          [128, 32, 32, 32]              64\n",
      "             ReLU-18          [128, 32, 32, 32]               0\n",
      "        MaxPool2d-19         [128, 192, 32, 32]               0\n",
      "           Conv2d-20          [128, 32, 32, 32]           6,176\n",
      "      BatchNorm2d-21          [128, 32, 32, 32]              64\n",
      "             ReLU-22          [128, 32, 32, 32]               0\n",
      "        Inception-23         [128, 256, 32, 32]               0\n",
      "           Conv2d-24         [128, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-25         [128, 128, 32, 32]             256\n",
      "             ReLU-26         [128, 128, 32, 32]               0\n",
      "           Conv2d-27         [128, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-28         [128, 128, 32, 32]             256\n",
      "             ReLU-29         [128, 128, 32, 32]               0\n",
      "           Conv2d-30         [128, 192, 32, 32]         221,376\n",
      "      BatchNorm2d-31         [128, 192, 32, 32]             384\n",
      "             ReLU-32         [128, 192, 32, 32]               0\n",
      "           Conv2d-33          [128, 32, 32, 32]           8,224\n",
      "      BatchNorm2d-34          [128, 32, 32, 32]              64\n",
      "             ReLU-35          [128, 32, 32, 32]               0\n",
      "           Conv2d-36          [128, 96, 32, 32]          76,896\n",
      "      BatchNorm2d-37          [128, 96, 32, 32]             192\n",
      "             ReLU-38          [128, 96, 32, 32]               0\n",
      "        MaxPool2d-39         [128, 256, 32, 32]               0\n",
      "           Conv2d-40          [128, 64, 32, 32]          16,448\n",
      "      BatchNorm2d-41          [128, 64, 32, 32]             128\n",
      "             ReLU-42          [128, 64, 32, 32]               0\n",
      "        Inception-43         [128, 480, 32, 32]               0\n",
      "        MaxPool2d-44         [128, 480, 16, 16]               0\n",
      "           Conv2d-45         [128, 192, 16, 16]          92,352\n",
      "      BatchNorm2d-46         [128, 192, 16, 16]             384\n",
      "             ReLU-47         [128, 192, 16, 16]               0\n",
      "           Conv2d-48          [128, 96, 16, 16]          46,176\n",
      "      BatchNorm2d-49          [128, 96, 16, 16]             192\n",
      "             ReLU-50          [128, 96, 16, 16]               0\n",
      "           Conv2d-51         [128, 208, 16, 16]         179,920\n",
      "      BatchNorm2d-52         [128, 208, 16, 16]             416\n",
      "             ReLU-53         [128, 208, 16, 16]               0\n",
      "           Conv2d-54          [128, 16, 16, 16]           7,696\n",
      "      BatchNorm2d-55          [128, 16, 16, 16]              32\n",
      "             ReLU-56          [128, 16, 16, 16]               0\n",
      "           Conv2d-57          [128, 48, 16, 16]          19,248\n",
      "      BatchNorm2d-58          [128, 48, 16, 16]              96\n",
      "             ReLU-59          [128, 48, 16, 16]               0\n",
      "        MaxPool2d-60         [128, 480, 16, 16]               0\n",
      "           Conv2d-61          [128, 64, 16, 16]          30,784\n",
      "      BatchNorm2d-62          [128, 64, 16, 16]             128\n",
      "             ReLU-63          [128, 64, 16, 16]               0\n",
      "        Inception-64         [128, 512, 16, 16]               0\n",
      "           Conv2d-65         [128, 160, 16, 16]          82,080\n",
      "      BatchNorm2d-66         [128, 160, 16, 16]             320\n",
      "             ReLU-67         [128, 160, 16, 16]               0\n",
      "           Conv2d-68         [128, 112, 16, 16]          57,456\n",
      "      BatchNorm2d-69         [128, 112, 16, 16]             224\n",
      "             ReLU-70         [128, 112, 16, 16]               0\n",
      "           Conv2d-71         [128, 224, 16, 16]         226,016\n",
      "      BatchNorm2d-72         [128, 224, 16, 16]             448\n",
      "             ReLU-73         [128, 224, 16, 16]               0\n",
      "           Conv2d-74          [128, 24, 16, 16]          12,312\n",
      "      BatchNorm2d-75          [128, 24, 16, 16]              48\n",
      "             ReLU-76          [128, 24, 16, 16]               0\n",
      "           Conv2d-77          [128, 64, 16, 16]          38,464\n",
      "      BatchNorm2d-78          [128, 64, 16, 16]             128\n",
      "             ReLU-79          [128, 64, 16, 16]               0\n",
      "        MaxPool2d-80         [128, 512, 16, 16]               0\n",
      "           Conv2d-81          [128, 64, 16, 16]          32,832\n",
      "      BatchNorm2d-82          [128, 64, 16, 16]             128\n",
      "             ReLU-83          [128, 64, 16, 16]               0\n",
      "        Inception-84         [128, 512, 16, 16]               0\n",
      "           Conv2d-85         [128, 128, 16, 16]          65,664\n",
      "      BatchNorm2d-86         [128, 128, 16, 16]             256\n",
      "             ReLU-87         [128, 128, 16, 16]               0\n",
      "           Conv2d-88         [128, 128, 16, 16]          65,664\n",
      "      BatchNorm2d-89         [128, 128, 16, 16]             256\n",
      "             ReLU-90         [128, 128, 16, 16]               0\n",
      "           Conv2d-91         [128, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-92         [128, 256, 16, 16]             512\n",
      "             ReLU-93         [128, 256, 16, 16]               0\n",
      "           Conv2d-94          [128, 24, 16, 16]          12,312\n",
      "      BatchNorm2d-95          [128, 24, 16, 16]              48\n",
      "             ReLU-96          [128, 24, 16, 16]               0\n",
      "           Conv2d-97          [128, 64, 16, 16]          38,464\n",
      "      BatchNorm2d-98          [128, 64, 16, 16]             128\n",
      "             ReLU-99          [128, 64, 16, 16]               0\n",
      "       MaxPool2d-100         [128, 512, 16, 16]               0\n",
      "          Conv2d-101          [128, 64, 16, 16]          32,832\n",
      "     BatchNorm2d-102          [128, 64, 16, 16]             128\n",
      "            ReLU-103          [128, 64, 16, 16]               0\n",
      "       Inception-104         [128, 512, 16, 16]               0\n",
      "          Conv2d-105         [128, 112, 16, 16]          57,456\n",
      "     BatchNorm2d-106         [128, 112, 16, 16]             224\n",
      "            ReLU-107         [128, 112, 16, 16]               0\n",
      "          Conv2d-108         [128, 144, 16, 16]          73,872\n",
      "     BatchNorm2d-109         [128, 144, 16, 16]             288\n",
      "            ReLU-110         [128, 144, 16, 16]               0\n",
      "          Conv2d-111         [128, 288, 16, 16]         373,536\n",
      "     BatchNorm2d-112         [128, 288, 16, 16]             576\n",
      "            ReLU-113         [128, 288, 16, 16]               0\n",
      "          Conv2d-114          [128, 32, 16, 16]          16,416\n",
      "     BatchNorm2d-115          [128, 32, 16, 16]              64\n",
      "            ReLU-116          [128, 32, 16, 16]               0\n",
      "          Conv2d-117          [128, 64, 16, 16]          51,264\n",
      "     BatchNorm2d-118          [128, 64, 16, 16]             128\n",
      "            ReLU-119          [128, 64, 16, 16]               0\n",
      "       MaxPool2d-120         [128, 512, 16, 16]               0\n",
      "          Conv2d-121          [128, 64, 16, 16]          32,832\n",
      "     BatchNorm2d-122          [128, 64, 16, 16]             128\n",
      "            ReLU-123          [128, 64, 16, 16]               0\n",
      "       Inception-124         [128, 528, 16, 16]               0\n",
      "          Conv2d-125         [128, 256, 16, 16]         135,424\n",
      "     BatchNorm2d-126         [128, 256, 16, 16]             512\n",
      "            ReLU-127         [128, 256, 16, 16]               0\n",
      "          Conv2d-128         [128, 160, 16, 16]          84,640\n",
      "     BatchNorm2d-129         [128, 160, 16, 16]             320\n",
      "            ReLU-130         [128, 160, 16, 16]               0\n",
      "          Conv2d-131         [128, 320, 16, 16]         461,120\n",
      "     BatchNorm2d-132         [128, 320, 16, 16]             640\n",
      "            ReLU-133         [128, 320, 16, 16]               0\n",
      "          Conv2d-134          [128, 32, 16, 16]          16,928\n",
      "     BatchNorm2d-135          [128, 32, 16, 16]              64\n",
      "            ReLU-136          [128, 32, 16, 16]               0\n",
      "          Conv2d-137         [128, 128, 16, 16]         102,528\n",
      "     BatchNorm2d-138         [128, 128, 16, 16]             256\n",
      "            ReLU-139         [128, 128, 16, 16]               0\n",
      "       MaxPool2d-140         [128, 528, 16, 16]               0\n",
      "          Conv2d-141         [128, 128, 16, 16]          67,712\n",
      "     BatchNorm2d-142         [128, 128, 16, 16]             256\n",
      "            ReLU-143         [128, 128, 16, 16]               0\n",
      "       Inception-144         [128, 832, 16, 16]               0\n",
      "       MaxPool2d-145           [128, 832, 8, 8]               0\n",
      "          Conv2d-146           [128, 256, 8, 8]         213,248\n",
      "     BatchNorm2d-147           [128, 256, 8, 8]             512\n",
      "            ReLU-148           [128, 256, 8, 8]               0\n",
      "          Conv2d-149           [128, 160, 8, 8]         133,280\n",
      "     BatchNorm2d-150           [128, 160, 8, 8]             320\n",
      "            ReLU-151           [128, 160, 8, 8]               0\n",
      "          Conv2d-152           [128, 320, 8, 8]         461,120\n",
      "     BatchNorm2d-153           [128, 320, 8, 8]             640\n",
      "            ReLU-154           [128, 320, 8, 8]               0\n",
      "          Conv2d-155            [128, 32, 8, 8]          26,656\n",
      "     BatchNorm2d-156            [128, 32, 8, 8]              64\n",
      "            ReLU-157            [128, 32, 8, 8]               0\n",
      "          Conv2d-158           [128, 128, 8, 8]         102,528\n",
      "     BatchNorm2d-159           [128, 128, 8, 8]             256\n",
      "            ReLU-160           [128, 128, 8, 8]               0\n",
      "       MaxPool2d-161           [128, 832, 8, 8]               0\n",
      "          Conv2d-162           [128, 128, 8, 8]         106,624\n",
      "     BatchNorm2d-163           [128, 128, 8, 8]             256\n",
      "            ReLU-164           [128, 128, 8, 8]               0\n",
      "       Inception-165           [128, 832, 8, 8]               0\n",
      "          Conv2d-166           [128, 384, 8, 8]         319,872\n",
      "     BatchNorm2d-167           [128, 384, 8, 8]             768\n",
      "            ReLU-168           [128, 384, 8, 8]               0\n",
      "          Conv2d-169           [128, 192, 8, 8]         159,936\n",
      "     BatchNorm2d-170           [128, 192, 8, 8]             384\n",
      "            ReLU-171           [128, 192, 8, 8]               0\n",
      "          Conv2d-172           [128, 384, 8, 8]         663,936\n",
      "     BatchNorm2d-173           [128, 384, 8, 8]             768\n",
      "            ReLU-174           [128, 384, 8, 8]               0\n",
      "          Conv2d-175            [128, 48, 8, 8]          39,984\n",
      "     BatchNorm2d-176            [128, 48, 8, 8]              96\n",
      "            ReLU-177            [128, 48, 8, 8]               0\n",
      "          Conv2d-178           [128, 128, 8, 8]         153,728\n",
      "     BatchNorm2d-179           [128, 128, 8, 8]             256\n",
      "            ReLU-180           [128, 128, 8, 8]               0\n",
      "       MaxPool2d-181           [128, 832, 8, 8]               0\n",
      "          Conv2d-182           [128, 128, 8, 8]         106,624\n",
      "     BatchNorm2d-183           [128, 128, 8, 8]             256\n",
      "            ReLU-184           [128, 128, 8, 8]               0\n",
      "       Inception-185          [128, 1024, 8, 8]               0\n",
      "       AvgPool2d-186          [128, 1024, 1, 1]               0\n",
      "          Linear-187                  [128, 10]          10,250\n",
      "================================================================\n",
      "Total params: 5,879,066\n",
      "Trainable params: 5,879,066\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 9714.01\n",
      "Params size (MB): 22.43\n",
      "Estimated Total Size (MB): 9737.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = GoogLeNet().to(device)\n",
    "\n",
    "print(train_set.data[0].shape)\n",
    "\n",
    "summary(model, (3, 32, 32), batch_size = 128, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, We create:\n",
    " 1. an optimizer  (we use adam optimzer here)\n",
    " 2. A Criterion (CrossEntropy) function\n",
    " 3. A Scheduler which is used to decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8,14,18], gamma=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch: [1/20], Step: [30/390], Train Loss: 1.6886\n",
      "Epoch: [1/20], Step: [60/390], Train Loss: 1.5857\n",
      "Epoch: [1/20], Step: [90/390], Train Loss: 1.3980\n",
      "Epoch: [1/20], Step: [120/390], Train Loss: 1.2621\n",
      "Epoch: [1/20], Step: [150/390], Train Loss: 1.2527\n",
      "Epoch: [1/20], Step: [180/390], Train Loss: 1.3351\n",
      "Epoch: [1/20], Step: [210/390], Train Loss: 1.2253\n",
      "Epoch: [1/20], Step: [240/390], Train Loss: 1.1396\n",
      "Epoch: [1/20], Step: [270/390], Train Loss: 0.9808\n",
      "Epoch: [1/20], Step: [300/390], Train Loss: 1.1789\n",
      "Epoch: [1/20], Step: [330/390], Train Loss: 0.8767\n",
      "Epoch: [1/20], Step: [360/390], Train Loss: 0.8886\n",
      "Epoch: [1/20], Step: [390/390], Train Loss: 0.7798\n",
      "\n",
      "Testing\n",
      "Epoch: [1/20], Step: [30/78], Test Loss: 0.9047\n",
      "Epoch: [1/20], Step: [60/78], Test Loss: 0.8626\n",
      "\n",
      "Epoch: 1\n",
      "Train Acc: 55.418\n",
      "Test Acc: 67.800\n",
      "\n",
      "Training\n",
      "Epoch: [2/20], Step: [30/390], Train Loss: 0.6644\n",
      "Epoch: [2/20], Step: [60/390], Train Loss: 0.7446\n",
      "Epoch: [2/20], Step: [90/390], Train Loss: 0.7596\n",
      "Epoch: [2/20], Step: [120/390], Train Loss: 1.0288\n",
      "Epoch: [2/20], Step: [150/390], Train Loss: 0.6526\n",
      "Epoch: [2/20], Step: [180/390], Train Loss: 0.7404\n",
      "Epoch: [2/20], Step: [210/390], Train Loss: 0.7512\n",
      "Epoch: [2/20], Step: [240/390], Train Loss: 0.6935\n",
      "Epoch: [2/20], Step: [270/390], Train Loss: 0.5631\n",
      "Epoch: [2/20], Step: [300/390], Train Loss: 0.8384\n",
      "Epoch: [2/20], Step: [330/390], Train Loss: 0.7140\n",
      "Epoch: [2/20], Step: [360/390], Train Loss: 0.5863\n",
      "Epoch: [2/20], Step: [390/390], Train Loss: 0.6341\n",
      "\n",
      "Testing\n",
      "Epoch: [2/20], Step: [30/78], Test Loss: 1.2695\n",
      "Epoch: [2/20], Step: [60/78], Test Loss: 1.3657\n",
      "\n",
      "Epoch: 2\n",
      "Train Acc: 73.602\n",
      "Test Acc: 64.220\n",
      "\n",
      "Training\n",
      "Epoch: [3/20], Step: [30/390], Train Loss: 0.5710\n",
      "Epoch: [3/20], Step: [60/390], Train Loss: 0.5256\n",
      "Epoch: [3/20], Step: [90/390], Train Loss: 0.6444\n",
      "Epoch: [3/20], Step: [120/390], Train Loss: 0.5803\n",
      "Epoch: [3/20], Step: [150/390], Train Loss: 0.4493\n",
      "Epoch: [3/20], Step: [180/390], Train Loss: 0.4508\n",
      "Epoch: [3/20], Step: [210/390], Train Loss: 0.6656\n",
      "Epoch: [3/20], Step: [240/390], Train Loss: 0.6369\n",
      "Epoch: [3/20], Step: [270/390], Train Loss: 0.4927\n",
      "Epoch: [3/20], Step: [300/390], Train Loss: 0.5449\n",
      "Epoch: [3/20], Step: [330/390], Train Loss: 0.4328\n",
      "Epoch: [3/20], Step: [360/390], Train Loss: 0.6171\n",
      "Epoch: [3/20], Step: [390/390], Train Loss: 0.5973\n",
      "\n",
      "Testing\n",
      "Epoch: [3/20], Step: [30/78], Test Loss: 0.7711\n",
      "Epoch: [3/20], Step: [60/78], Test Loss: 0.7930\n",
      "\n",
      "Epoch: 3\n",
      "Train Acc: 80.442\n",
      "Test Acc: 80.070\n",
      "\n",
      "Training\n",
      "Epoch: [4/20], Step: [30/390], Train Loss: 0.3287\n",
      "Epoch: [4/20], Step: [60/390], Train Loss: 0.3742\n",
      "Epoch: [4/20], Step: [90/390], Train Loss: 0.4939\n",
      "Epoch: [4/20], Step: [120/390], Train Loss: 0.4714\n",
      "Epoch: [4/20], Step: [150/390], Train Loss: 0.3416\n",
      "Epoch: [4/20], Step: [180/390], Train Loss: 0.3732\n",
      "Epoch: [4/20], Step: [210/390], Train Loss: 0.4210\n",
      "Epoch: [4/20], Step: [240/390], Train Loss: 0.3857\n",
      "Epoch: [4/20], Step: [270/390], Train Loss: 0.6068\n",
      "Epoch: [4/20], Step: [300/390], Train Loss: 0.4404\n",
      "Epoch: [4/20], Step: [330/390], Train Loss: 0.3554\n",
      "Epoch: [4/20], Step: [360/390], Train Loss: 0.4253\n",
      "Epoch: [4/20], Step: [390/390], Train Loss: 0.3582\n",
      "\n",
      "Testing\n",
      "Epoch: [4/20], Step: [30/78], Test Loss: 0.6274\n",
      "Epoch: [4/20], Step: [60/78], Test Loss: 0.7031\n",
      "\n",
      "Epoch: 4\n",
      "Train Acc: 83.998\n",
      "Test Acc: 79.360\n",
      "\n",
      "Training\n",
      "Epoch: [5/20], Step: [30/390], Train Loss: 0.4213\n",
      "Epoch: [5/20], Step: [60/390], Train Loss: 0.4703\n",
      "Epoch: [5/20], Step: [90/390], Train Loss: 0.6556\n",
      "Epoch: [5/20], Step: [120/390], Train Loss: 0.3815\n",
      "Epoch: [5/20], Step: [150/390], Train Loss: 0.3514\n",
      "Epoch: [5/20], Step: [180/390], Train Loss: 0.4696\n",
      "Epoch: [5/20], Step: [210/390], Train Loss: 0.5350\n",
      "Epoch: [5/20], Step: [240/390], Train Loss: 0.4241\n",
      "Epoch: [5/20], Step: [270/390], Train Loss: 0.3108\n",
      "Epoch: [5/20], Step: [300/390], Train Loss: 0.3405\n",
      "Epoch: [5/20], Step: [330/390], Train Loss: 0.5020\n",
      "Epoch: [5/20], Step: [360/390], Train Loss: 0.4178\n",
      "Epoch: [5/20], Step: [390/390], Train Loss: 0.4362\n",
      "\n",
      "Testing\n",
      "Epoch: [5/20], Step: [30/78], Test Loss: 0.5578\n",
      "Epoch: [5/20], Step: [60/78], Test Loss: 0.5021\n",
      "\n",
      "Epoch: 5\n",
      "Train Acc: 86.474\n",
      "Test Acc: 83.750\n",
      "\n",
      "Training\n",
      "Epoch: [6/20], Step: [30/390], Train Loss: 0.1858\n",
      "Epoch: [6/20], Step: [60/390], Train Loss: 0.3296\n",
      "Epoch: [6/20], Step: [90/390], Train Loss: 0.3635\n",
      "Epoch: [6/20], Step: [120/390], Train Loss: 0.2530\n",
      "Epoch: [6/20], Step: [150/390], Train Loss: 0.3261\n",
      "Epoch: [6/20], Step: [180/390], Train Loss: 0.3198\n",
      "Epoch: [6/20], Step: [210/390], Train Loss: 0.4401\n",
      "Epoch: [6/20], Step: [240/390], Train Loss: 0.2655\n",
      "Epoch: [6/20], Step: [270/390], Train Loss: 0.3155\n",
      "Epoch: [6/20], Step: [300/390], Train Loss: 0.3392\n",
      "Epoch: [6/20], Step: [330/390], Train Loss: 0.2639\n",
      "Epoch: [6/20], Step: [360/390], Train Loss: 0.4150\n",
      "Epoch: [6/20], Step: [390/390], Train Loss: 0.4527\n",
      "\n",
      "Testing\n",
      "Epoch: [6/20], Step: [30/78], Test Loss: 0.4658\n",
      "Epoch: [6/20], Step: [60/78], Test Loss: 0.4412\n",
      "\n",
      "Epoch: 6\n",
      "Train Acc: 88.286\n",
      "Test Acc: 84.350\n",
      "\n",
      "Training\n",
      "Epoch: [7/20], Step: [30/390], Train Loss: 0.2012\n",
      "Epoch: [7/20], Step: [60/390], Train Loss: 0.3011\n",
      "Epoch: [7/20], Step: [90/390], Train Loss: 0.2990\n",
      "Epoch: [7/20], Step: [120/390], Train Loss: 0.2445\n",
      "Epoch: [7/20], Step: [150/390], Train Loss: 0.3890\n",
      "Epoch: [7/20], Step: [180/390], Train Loss: 0.2946\n",
      "Epoch: [7/20], Step: [210/390], Train Loss: 0.3633\n",
      "Epoch: [7/20], Step: [240/390], Train Loss: 0.3678\n",
      "Epoch: [7/20], Step: [270/390], Train Loss: 0.3404\n",
      "Epoch: [7/20], Step: [300/390], Train Loss: 0.2329\n",
      "Epoch: [7/20], Step: [330/390], Train Loss: 0.3773\n",
      "Epoch: [7/20], Step: [360/390], Train Loss: 0.2861\n",
      "Epoch: [7/20], Step: [390/390], Train Loss: 0.3342\n",
      "\n",
      "Testing\n",
      "Epoch: [7/20], Step: [30/78], Test Loss: 0.5612\n",
      "Epoch: [7/20], Step: [60/78], Test Loss: 0.4696\n",
      "\n",
      "Epoch: 7\n",
      "Train Acc: 89.848\n",
      "Test Acc: 85.290\n",
      "\n",
      "Training\n",
      "Epoch: [8/20], Step: [30/390], Train Loss: 0.1843\n",
      "Epoch: [8/20], Step: [60/390], Train Loss: 0.2403\n",
      "Epoch: [8/20], Step: [90/390], Train Loss: 0.2440\n",
      "Epoch: [8/20], Step: [120/390], Train Loss: 0.2779\n",
      "Epoch: [8/20], Step: [150/390], Train Loss: 0.2642\n",
      "Epoch: [8/20], Step: [180/390], Train Loss: 0.2475\n",
      "Epoch: [8/20], Step: [210/390], Train Loss: 0.2132\n",
      "Epoch: [8/20], Step: [240/390], Train Loss: 0.3507\n",
      "Epoch: [8/20], Step: [270/390], Train Loss: 0.2613\n",
      "Epoch: [8/20], Step: [300/390], Train Loss: 0.2865\n",
      "Epoch: [8/20], Step: [330/390], Train Loss: 0.0797\n",
      "Epoch: [8/20], Step: [360/390], Train Loss: 0.4362\n",
      "Epoch: [8/20], Step: [390/390], Train Loss: 0.2468\n",
      "\n",
      "Testing\n",
      "Epoch: [8/20], Step: [30/78], Test Loss: 0.5417\n",
      "Epoch: [8/20], Step: [60/78], Test Loss: 0.5191\n",
      "\n",
      "Epoch: 8\n",
      "Train Acc: 91.210\n",
      "Test Acc: 83.860\n",
      "\n",
      "Training\n",
      "Epoch: [9/20], Step: [30/390], Train Loss: 0.1723\n",
      "Epoch: [9/20], Step: [60/390], Train Loss: 0.1310\n",
      "Epoch: [9/20], Step: [90/390], Train Loss: 0.2311\n",
      "Epoch: [9/20], Step: [120/390], Train Loss: 0.0712\n",
      "Epoch: [9/20], Step: [150/390], Train Loss: 0.2413\n",
      "Epoch: [9/20], Step: [180/390], Train Loss: 0.0938\n",
      "Epoch: [9/20], Step: [210/390], Train Loss: 0.1444\n",
      "Epoch: [9/20], Step: [240/390], Train Loss: 0.1019\n",
      "Epoch: [9/20], Step: [270/390], Train Loss: 0.1346\n",
      "Epoch: [9/20], Step: [300/390], Train Loss: 0.1258\n",
      "Epoch: [9/20], Step: [330/390], Train Loss: 0.1298\n",
      "Epoch: [9/20], Step: [360/390], Train Loss: 0.0870\n",
      "Epoch: [9/20], Step: [390/390], Train Loss: 0.0749\n",
      "\n",
      "Testing\n",
      "Epoch: [9/20], Step: [30/78], Test Loss: 0.3527\n",
      "Epoch: [9/20], Step: [60/78], Test Loss: 0.3815\n",
      "\n",
      "Epoch: 9\n",
      "Train Acc: 95.104\n",
      "Test Acc: 91.040\n",
      "\n",
      "Training\n",
      "Epoch: [10/20], Step: [30/390], Train Loss: 0.1147\n",
      "Epoch: [10/20], Step: [60/390], Train Loss: 0.0584\n",
      "Epoch: [10/20], Step: [90/390], Train Loss: 0.0793\n",
      "Epoch: [10/20], Step: [120/390], Train Loss: 0.0582\n",
      "Epoch: [10/20], Step: [150/390], Train Loss: 0.0836\n",
      "Epoch: [10/20], Step: [180/390], Train Loss: 0.0813\n",
      "Epoch: [10/20], Step: [210/390], Train Loss: 0.1426\n",
      "Epoch: [10/20], Step: [240/390], Train Loss: 0.0715\n",
      "Epoch: [10/20], Step: [270/390], Train Loss: 0.1290\n",
      "Epoch: [10/20], Step: [300/390], Train Loss: 0.1129\n",
      "Epoch: [10/20], Step: [330/390], Train Loss: 0.1034\n",
      "Epoch: [10/20], Step: [360/390], Train Loss: 0.0955\n",
      "Epoch: [10/20], Step: [390/390], Train Loss: 0.0618\n",
      "\n",
      "Testing\n",
      "Epoch: [10/20], Step: [30/78], Test Loss: 0.3488\n",
      "Epoch: [10/20], Step: [60/78], Test Loss: 0.3683\n",
      "\n",
      "Epoch: 10\n",
      "Train Acc: 96.420\n",
      "Test Acc: 91.070\n",
      "\n",
      "Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11/20], Step: [30/390], Train Loss: 0.0818\n",
      "Epoch: [11/20], Step: [60/390], Train Loss: 0.1128\n",
      "Epoch: [11/20], Step: [90/390], Train Loss: 0.1661\n",
      "Epoch: [11/20], Step: [120/390], Train Loss: 0.1017\n",
      "Epoch: [11/20], Step: [150/390], Train Loss: 0.0953\n",
      "Epoch: [11/20], Step: [180/390], Train Loss: 0.0879\n",
      "Epoch: [11/20], Step: [210/390], Train Loss: 0.0606\n",
      "Epoch: [11/20], Step: [240/390], Train Loss: 0.0812\n",
      "Epoch: [11/20], Step: [270/390], Train Loss: 0.0749\n",
      "Epoch: [11/20], Step: [300/390], Train Loss: 0.1103\n",
      "Epoch: [11/20], Step: [330/390], Train Loss: 0.0632\n",
      "Epoch: [11/20], Step: [360/390], Train Loss: 0.1703\n",
      "Epoch: [11/20], Step: [390/390], Train Loss: 0.0573\n",
      "\n",
      "Testing\n",
      "Epoch: [11/20], Step: [30/78], Test Loss: 0.3741\n",
      "Epoch: [11/20], Step: [60/78], Test Loss: 0.3618\n",
      "\n",
      "Epoch: 11\n",
      "Train Acc: 97.086\n",
      "Test Acc: 91.190\n",
      "\n",
      "Training\n",
      "Epoch: [12/20], Step: [30/390], Train Loss: 0.0440\n",
      "Epoch: [12/20], Step: [60/390], Train Loss: 0.0712\n",
      "Epoch: [12/20], Step: [90/390], Train Loss: 0.0754\n",
      "Epoch: [12/20], Step: [120/390], Train Loss: 0.0907\n",
      "Epoch: [12/20], Step: [150/390], Train Loss: 0.0918\n",
      "Epoch: [12/20], Step: [180/390], Train Loss: 0.1519\n",
      "Epoch: [12/20], Step: [210/390], Train Loss: 0.0835\n",
      "Epoch: [12/20], Step: [240/390], Train Loss: 0.0661\n",
      "Epoch: [12/20], Step: [270/390], Train Loss: 0.0439\n",
      "Epoch: [12/20], Step: [300/390], Train Loss: 0.0856\n",
      "Epoch: [12/20], Step: [330/390], Train Loss: 0.1081\n",
      "Epoch: [12/20], Step: [360/390], Train Loss: 0.0397\n",
      "Epoch: [12/20], Step: [390/390], Train Loss: 0.0921\n",
      "\n",
      "Testing\n",
      "Epoch: [12/20], Step: [30/78], Test Loss: 0.3778\n",
      "Epoch: [12/20], Step: [60/78], Test Loss: 0.4450\n",
      "\n",
      "Epoch: 12\n",
      "Train Acc: 97.500\n",
      "Test Acc: 91.290\n",
      "\n",
      "Training\n",
      "Epoch: [13/20], Step: [30/390], Train Loss: 0.0745\n",
      "Epoch: [13/20], Step: [60/390], Train Loss: 0.0504\n",
      "Epoch: [13/20], Step: [90/390], Train Loss: 0.0352\n",
      "Epoch: [13/20], Step: [120/390], Train Loss: 0.0758\n",
      "Epoch: [13/20], Step: [150/390], Train Loss: 0.0652\n",
      "Epoch: [13/20], Step: [180/390], Train Loss: 0.0738\n",
      "Epoch: [13/20], Step: [210/390], Train Loss: 0.0420\n",
      "Epoch: [13/20], Step: [240/390], Train Loss: 0.1127\n",
      "Epoch: [13/20], Step: [270/390], Train Loss: 0.0434\n",
      "Epoch: [13/20], Step: [300/390], Train Loss: 0.0887\n",
      "Epoch: [13/20], Step: [330/390], Train Loss: 0.1006\n",
      "Epoch: [13/20], Step: [360/390], Train Loss: 0.1005\n",
      "Epoch: [13/20], Step: [390/390], Train Loss: 0.0443\n",
      "\n",
      "Testing\n",
      "Epoch: [13/20], Step: [30/78], Test Loss: 0.4460\n",
      "Epoch: [13/20], Step: [60/78], Test Loss: 0.4664\n",
      "\n",
      "Epoch: 13\n",
      "Train Acc: 97.924\n",
      "Test Acc: 91.240\n",
      "\n",
      "Training\n",
      "Epoch: [14/20], Step: [30/390], Train Loss: 0.0850\n",
      "Epoch: [14/20], Step: [60/390], Train Loss: 0.0338\n",
      "Epoch: [14/20], Step: [90/390], Train Loss: 0.0407\n",
      "Epoch: [14/20], Step: [120/390], Train Loss: 0.0470\n",
      "Epoch: [14/20], Step: [150/390], Train Loss: 0.0527\n",
      "Epoch: [14/20], Step: [180/390], Train Loss: 0.0589\n",
      "Epoch: [14/20], Step: [210/390], Train Loss: 0.0317\n",
      "Epoch: [14/20], Step: [240/390], Train Loss: 0.0462\n",
      "Epoch: [14/20], Step: [270/390], Train Loss: 0.1001\n",
      "Epoch: [14/20], Step: [300/390], Train Loss: 0.0428\n",
      "Epoch: [14/20], Step: [330/390], Train Loss: 0.0681\n",
      "Epoch: [14/20], Step: [360/390], Train Loss: 0.0635\n",
      "Epoch: [14/20], Step: [390/390], Train Loss: 0.0643\n",
      "\n",
      "Testing\n",
      "Epoch: [14/20], Step: [30/78], Test Loss: 0.4773\n",
      "Epoch: [14/20], Step: [60/78], Test Loss: 0.4490\n",
      "\n",
      "Epoch: 14\n",
      "Train Acc: 98.364\n",
      "Test Acc: 91.130\n",
      "\n",
      "Training\n",
      "Epoch: [15/20], Step: [30/390], Train Loss: 0.0225\n",
      "Epoch: [15/20], Step: [60/390], Train Loss: 0.0239\n",
      "Epoch: [15/20], Step: [90/390], Train Loss: 0.0200\n",
      "Epoch: [15/20], Step: [120/390], Train Loss: 0.0236\n",
      "Epoch: [15/20], Step: [150/390], Train Loss: 0.0555\n",
      "Epoch: [15/20], Step: [180/390], Train Loss: 0.0279\n",
      "Epoch: [15/20], Step: [210/390], Train Loss: 0.0736\n",
      "Epoch: [15/20], Step: [240/390], Train Loss: 0.0255\n",
      "Epoch: [15/20], Step: [270/390], Train Loss: 0.0162\n",
      "Epoch: [15/20], Step: [300/390], Train Loss: 0.0511\n",
      "Epoch: [15/20], Step: [330/390], Train Loss: 0.0438\n",
      "Epoch: [15/20], Step: [360/390], Train Loss: 0.0581\n",
      "Epoch: [15/20], Step: [390/390], Train Loss: 0.0835\n",
      "\n",
      "Testing\n",
      "Epoch: [15/20], Step: [30/78], Test Loss: 0.4440\n",
      "Epoch: [15/20], Step: [60/78], Test Loss: 0.4573\n",
      "\n",
      "Epoch: 15\n",
      "Train Acc: 98.910\n",
      "Test Acc: 91.530\n",
      "\n",
      "Training\n",
      "Epoch: [16/20], Step: [30/390], Train Loss: 0.0386\n",
      "Epoch: [16/20], Step: [60/390], Train Loss: 0.0491\n",
      "Epoch: [16/20], Step: [90/390], Train Loss: 0.0598\n",
      "Epoch: [16/20], Step: [120/390], Train Loss: 0.0266\n",
      "Epoch: [16/20], Step: [150/390], Train Loss: 0.0321\n",
      "Epoch: [16/20], Step: [180/390], Train Loss: 0.0391\n",
      "Epoch: [16/20], Step: [210/390], Train Loss: 0.0369\n",
      "Epoch: [16/20], Step: [240/390], Train Loss: 0.0337\n",
      "Epoch: [16/20], Step: [270/390], Train Loss: 0.0301\n",
      "Epoch: [16/20], Step: [300/390], Train Loss: 0.0377\n",
      "Epoch: [16/20], Step: [330/390], Train Loss: 0.0394\n",
      "Epoch: [16/20], Step: [360/390], Train Loss: 0.0577\n",
      "Epoch: [16/20], Step: [390/390], Train Loss: 0.0136\n",
      "\n",
      "Testing\n",
      "Epoch: [16/20], Step: [30/78], Test Loss: 0.4289\n",
      "Epoch: [16/20], Step: [60/78], Test Loss: 0.4566\n",
      "\n",
      "Epoch: 16\n",
      "Train Acc: 99.068\n",
      "Test Acc: 91.460\n",
      "\n",
      "Training\n",
      "Epoch: [17/20], Step: [30/390], Train Loss: 0.0437\n",
      "Epoch: [17/20], Step: [60/390], Train Loss: 0.0329\n",
      "Epoch: [17/20], Step: [90/390], Train Loss: 0.0588\n",
      "Epoch: [17/20], Step: [120/390], Train Loss: 0.0333\n",
      "Epoch: [17/20], Step: [150/390], Train Loss: 0.0304\n",
      "Epoch: [17/20], Step: [180/390], Train Loss: 0.0412\n",
      "Epoch: [17/20], Step: [210/390], Train Loss: 0.0386\n",
      "Epoch: [17/20], Step: [240/390], Train Loss: 0.0282\n",
      "Epoch: [17/20], Step: [270/390], Train Loss: 0.0138\n",
      "Epoch: [17/20], Step: [300/390], Train Loss: 0.0525\n",
      "Epoch: [17/20], Step: [330/390], Train Loss: 0.0094\n",
      "Epoch: [17/20], Step: [360/390], Train Loss: 0.0400\n",
      "Epoch: [17/20], Step: [390/390], Train Loss: 0.0507\n",
      "\n",
      "Testing\n",
      "Epoch: [17/20], Step: [30/78], Test Loss: 0.4258\n",
      "Epoch: [17/20], Step: [60/78], Test Loss: 0.4597\n",
      "\n",
      "Epoch: 17\n",
      "Train Acc: 99.072\n",
      "Test Acc: 91.500\n",
      "\n",
      "Training\n",
      "Epoch: [18/20], Step: [30/390], Train Loss: 0.0331\n",
      "Epoch: [18/20], Step: [60/390], Train Loss: 0.0157\n",
      "Epoch: [18/20], Step: [90/390], Train Loss: 0.0239\n",
      "Epoch: [18/20], Step: [120/390], Train Loss: 0.0359\n",
      "Epoch: [18/20], Step: [150/390], Train Loss: 0.0265\n",
      "Epoch: [18/20], Step: [180/390], Train Loss: 0.0576\n",
      "Epoch: [18/20], Step: [210/390], Train Loss: 0.0342\n",
      "Epoch: [18/20], Step: [240/390], Train Loss: 0.0153\n",
      "Epoch: [18/20], Step: [270/390], Train Loss: 0.0171\n",
      "Epoch: [18/20], Step: [300/390], Train Loss: 0.0280\n",
      "Epoch: [18/20], Step: [330/390], Train Loss: 0.0113\n",
      "Epoch: [18/20], Step: [360/390], Train Loss: 0.0313\n",
      "Epoch: [18/20], Step: [390/390], Train Loss: 0.0371\n",
      "\n",
      "Testing\n",
      "Epoch: [18/20], Step: [30/78], Test Loss: 0.4434\n",
      "Epoch: [18/20], Step: [60/78], Test Loss: 0.4695\n",
      "\n",
      "Epoch: 18\n",
      "Train Acc: 99.092\n",
      "Test Acc: 91.480\n",
      "\n",
      "Training\n",
      "Epoch: [19/20], Step: [30/390], Train Loss: 0.0190\n",
      "Epoch: [19/20], Step: [60/390], Train Loss: 0.0410\n",
      "Epoch: [19/20], Step: [90/390], Train Loss: 0.0183\n",
      "Epoch: [19/20], Step: [120/390], Train Loss: 0.0252\n",
      "Epoch: [19/20], Step: [150/390], Train Loss: 0.0359\n",
      "Epoch: [19/20], Step: [180/390], Train Loss: 0.0067\n",
      "Epoch: [19/20], Step: [210/390], Train Loss: 0.0706\n",
      "Epoch: [19/20], Step: [240/390], Train Loss: 0.0357\n",
      "Epoch: [19/20], Step: [270/390], Train Loss: 0.0101\n",
      "Epoch: [19/20], Step: [300/390], Train Loss: 0.0191\n",
      "Epoch: [19/20], Step: [330/390], Train Loss: 0.0487\n",
      "Epoch: [19/20], Step: [360/390], Train Loss: 0.0322\n",
      "Epoch: [19/20], Step: [390/390], Train Loss: 0.0545\n",
      "\n",
      "Testing\n",
      "Epoch: [19/20], Step: [30/78], Test Loss: 0.4296\n",
      "Epoch: [19/20], Step: [60/78], Test Loss: 0.4656\n",
      "\n",
      "Epoch: 19\n",
      "Train Acc: 99.186\n",
      "Test Acc: 91.570\n",
      "\n",
      "Training\n",
      "Epoch: [20/20], Step: [30/390], Train Loss: 0.0233\n",
      "Epoch: [20/20], Step: [60/390], Train Loss: 0.0254\n",
      "Epoch: [20/20], Step: [90/390], Train Loss: 0.0357\n",
      "Epoch: [20/20], Step: [120/390], Train Loss: 0.0194\n",
      "Epoch: [20/20], Step: [150/390], Train Loss: 0.0546\n",
      "Epoch: [20/20], Step: [180/390], Train Loss: 0.0181\n",
      "Epoch: [20/20], Step: [210/390], Train Loss: 0.0490\n",
      "Epoch: [20/20], Step: [240/390], Train Loss: 0.0391\n",
      "Epoch: [20/20], Step: [270/390], Train Loss: 0.0484\n",
      "Epoch: [20/20], Step: [300/390], Train Loss: 0.0205\n",
      "Epoch: [20/20], Step: [330/390], Train Loss: 0.0108\n",
      "Epoch: [20/20], Step: [360/390], Train Loss: 0.0573\n",
      "Epoch: [20/20], Step: [390/390], Train Loss: 0.0293\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20], Step: [30/78], Test Loss: 0.4420\n",
      "Epoch: [20/20], Step: [60/78], Test Loss: 0.4636\n",
      "\n",
      "Epoch: 20\n",
      "Train Acc: 99.166\n",
      "Test Acc: 91.480\n",
      "\n",
      "Finished Training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # train\n",
    "    # for train accuracy\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    train_run_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    print(\"Training\")\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model.forward(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluating\n",
    "        train_run_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "         \n",
    "        # Log\n",
    "        if (i+1) % 30 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Train Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(train_set)//train_batch, loss.data.item()))\n",
    "  \n",
    "\n",
    "    # test\n",
    "    model.eval()\n",
    "    print(\"\\nTesting\")\n",
    "    with torch.no_grad():\n",
    "        # for test accuracy\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        test_run_loss = .0\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Evaluating\n",
    "            test_run_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "            # Log\n",
    "            if (i+1) % 30 == 0:\n",
    "                print ('Epoch: [%d/%d], Step: [%d/%d], Test Loss: %.4f'\n",
    "                    %(epoch+1, num_epochs, i+1, len(test_set)//test_batch, loss.data.item()))\n",
    "\n",
    "        # Accumulating Loss and Calculating Accuracy\n",
    "        \n",
    "        # Training\n",
    "        train_loss.append(train_run_loss)\n",
    "        train_run_acc = correct_train / total_train\n",
    "        train_acc.append(train_run_acc)\n",
    "        \n",
    "        # Testing        \n",
    "        test_loss.append(test_run_loss)\n",
    "        test_run_acc = correct_test / total_test\n",
    "        test_acc.append(test_run_acc)\n",
    "        \n",
    "        # Logging Epoch Results\n",
    "        print('\\nEpoch:', epoch+1)\n",
    "        print('Train Acc: %.3f'%(100 * train_run_acc))\n",
    "        print('Test Acc: %.3f\\n'%(100 * test_run_acc))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Finished Training\\n\")\n",
    "\n",
    "# Saving the state_dict to save optimized parameters\n",
    "torch.save(model.state_dict(), 'checkpoints/model.pth')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Visualizing the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAx6ElEQVR4nO3deXxU9b3/8ddnJpMdQghhS1gFRTYRIuJaa11ArVptKVattbbU/myr91av2N721ntvr3a51va6W6m2VtSr9WpdUQt1BwNFdmSHEISwhASykEy+vz/OSRhCEgLJ5ITM+/l4zOOsM/OZQ5j3nPM953vMOYeIiAhAKOgCRESk81AoiIhIA4WCiIg0UCiIiEgDhYKIiDRQKIiISAOFgoiINFAoSIcysw1mdl5A7z3RzF41s1Iz22Vm883s+iBqEemsFAqSEMzsNOBvwN+BYUAO8F1gSpB1xTKzpKBrEFEoSKdgZilmdq+ZFfuPe80sxV/Wy8xejvmF/66Zhfxlt5vZFjMrN7NVZvaFZt7iV8ATzrlfOOd2OM8C59zUmBq+bWZr/Pd4ycz6xyxzZnajma02s91mdr95Uvy6Rsesm2tmlWbW25++xMwW+et9YGZjY9bd4H+GxcA+M0sys6+b2UYz22lmP4nduzKzkJnNMLO1/vJnzaynv2ywX+d1ZrbJzHaY2Y9j3itsZj/yn1tuZgvMbIC/bISZvel/9lVm1rBdJME45/TQo8MewAbgvCbm/zvwEdAbyAU+AP7DX3YX8BAQ8R9nAQacAGwG+vvrDQaOa+K104Eo8PkW6joX2AGMB1KA/wHeiVnugJeBHsBAoASY7C+bCfw8Zt2bgNf98fHAduBUIAxc52+DlJjtsQgYAKQBI4G9wJlAMvBroKZ+mwG3+Nsp36/zYWBWzOd3wKP+a50EVAMn+stvA5b428385TlAhr8drweS/Jp3AKOC/nvRo+MfgRegR2I9WgiFtcBFMdMXAhv88X8HXgSGNXrOMP8L9zwg0sJ75vlfliNaWOcx4Jcx05n+l/Fgf9oBZ8YsfxaY4Y+fB6yLWfY+8HV//EH8cItZvgr4XMz2+GbMsp/Wf8n70+nA/phQWAF8IWZ5P7/OpJhQyI9ZPh+YFvO+lzXx2b8KvNto3sPAvwX996JHxz90+Eg6i/7Axpjpjf488A79rAFmm9k6M5sB4Jxbg/fL+WfAdjN7OvaQT4zdQB3eF2ir3t85txfYiRco9T6LGa/ACw7w2irSzOxUMxsEjANe8JcNAn7oHzoqNbNSvL2C2Do3N6qjYdo5V+HXUW8Q8ELMa63A2wvq04o6B+CFb2ODgFMb1Xg10LeJdaWLUyhIZ1GM9+VUb6A/D+dcuXPuh865ocAXgX+ubztwzj3lnDvTf64DftH4hf0v1g+BK1v7/maWgXdoZcvhCnfO1eHtOVwFfA142TlX7i/ejHdoqUfMI905Nyv2JWLGt+IdGqqvI82vo95mYEqj10t1zh22Tv+5xzUz/++NXjPTOffdVrymdDEKBQlCxMxSYx5JwCzgX/1G2l54h1GehIaG2mFmZkAZ3i/jqJmdYGbn+g3SVUClv6wp/wJ8w8xuM7Mc/3VPMrOn/eVPAdeb2Tj/9f4LmOec29DKz/QU3mGYq/3xeo8CN/p7EWZmGWZ2sZl1a+Z1ngO+aGanm1kycCfe8f96DwE/9/dI6hu1L2tljb8H/sPMhvu1jPW3xcvA8WZ2rZlF/McpZnZiK19XuhCFggThVbwv8PrHz4D/BAqBxXiNoQv9eQDDgbfwGmA/BB5wzs3Fa2i9G69R9DO8RuofNfWGzrkP8BqTzwXWmdku4BG/FpxzbwM/AZ7H+7V+HDCttR/IOTcP2Id3+Oe1mPmFwLeB+/AOY60BvtHC6ywDvg887ddRjtduUu2v8lvgJbxDaeV4jc6ntrLMe/D2aGbjhetjQJq/V3MB3uctxtuWv8DbvpJgzDndZEekszKzTKAUGO6cWx9wOZIAtKcg0smY2RfNLN1v1/g13p7ThmCrkkShUBDpfC7DO4xTjHfobJrTLr10EB0+EhGRBtpTEBGRBgoFERFpoFAQEZEGCgUREWmgUBARkQYKBRERaaBQEBGRBgoFERFpoFAQEZEGCgUREWmgUBARkQYKBRERaRDXUDCzDWa2xMwWmVmhP6+nmb1pZqv9YXbM+neY2RozW2VmF8azNhEROVRH7Cl83jk3zjlX4E/PAN52zg0H3vanMbOReHd+GgVMBh4ws3AH1CciIr6kAN7zMuAcf/wJYC5wuz//aedcNbDezNYAE/Fuv9ikXr16ucGDB8ezVhGRLmfBggU7nHO5TS2Ldyg4vHvJOuBh59wjQB/n3FYA59xWM+vtr5uHd7/ZekX+vIOY2XRgOsDAgQMpLCyMZ/0iIl2OmW1sblm8Q+EM51yx/8X/ppmtbGFda2LeIXcA8oPlEYCCggLdIUhEpB3FtU3BOVfsD7cDL+AdDtpmZv0A/OF2f/UiYEDM0/PxbkcoIiIdJG6hYGYZZtatfhy4AFgKvARc5692HfCiP/4SMM3MUsxsCN69aefHqz4RETlUPA8f9QFeMLP693nKOfe6mX0MPGtmNwCbgK8AOOeWmdmzwHKgFrjJOReNY30ikqBqamooKiqiqqoq6FLiKjU1lfz8fCKRSKufY84du4flCwoKnBqaReRIrV+/nm7dupGTk4P/w7XLcc6xc+dOysvLGTJkyEHLzGxBzGUCB9EVzSKScKqqqrp0IACYGTk5OUe8N6RQEJGE1JUDod7RfMaEDIWi3RX8+o1VbN5VEXQpIiKdSkKGwr7qKPfNWUPhxl1BlyIiCai0tJQHHnjgiJ930UUXUVpa2v4FxUjIUDguN4O0SJglRWVBlyIiCai5UIhGWz7h8tVXX6VHjx5xqsoTRN9HgUsKhxjVvztLtpQGXYqIJKAZM2awdu1axo0bRyQSITMzk379+rFo0SKWL1/O5ZdfzubNm6mqquLmm29m+vTpAAwePJjCwkL27t3LlClTOPPMM/nggw/Iy8vjxRdfJC0trc21JWQoAIzOy+KZjzcTrXOEQ12/wUlEmnbnX5exvLh9jxqM7N+df/viqGaX33333SxdupRFixYxd+5cLr74YpYuXdpw6ujMmTPp2bMnlZWVnHLKKVx55ZXk5OQc9BqrV69m1qxZPProo0ydOpXnn3+ea665ps21J+ThI4Cx+VlU1kRZW7I36FJEJMFNnDjxoGsJfve733HSSScxadIkNm/ezOrVqw95zpAhQxg3bhwAEyZMYMOGDe1SS8LuKYzNzwJgSdEeju/TLeBqRCQoLf2i7ygZGRkN43PnzuWtt97iww8/JD09nXPOOafJaw1SUlIaxsPhMJWVle1SS8LuKQzplUlGcpglW/YEXYqIJJhu3bpRXl7e5LI9e/aQnZ1Neno6K1eu5KOPPmpyvXhJ2D2FcMgY1T+LxUWlQZciIgkmJyeHM844g9GjR5OWlkafPn0alk2ePJmHHnqIsWPHcsIJJzBp0qQOrS1hQwFgTH4Wf563kdpoHUnhhN1pEpEAPPXUU03OT0lJ4bXXXmtyWX27Qa9evVi6dGnD/FtvvbXd6krob8Kx+VlU1dSxRo3NIiJAgofCmDyvsXlxkdoVREQgwUNhcE4GmSlJLFEoiIgACR4KoZAxOq87i3UGkogIkOChADA2vwcrtpZRE60LuhQRkcAlfCiMyctif20dn25r+pxhEZFEolDIO3Bls4hIRzjarrMB7r33Xioq4ncvmIQPhUE56XRLTVK7goh0mM4cCgl98Rp4t6sbm5+lPQUR6TCxXWeff/759O7dm2effZbq6mq+9KUvceedd7Jv3z6mTp1KUVER0WiUn/zkJ2zbto3i4mI+//nP06tXL+bMmdPutSV8KACMyevBY++to7o2SkpSOOhyRKQjvTYDPlvSvq/ZdwxMubvZxbFdZ8+ePZvnnnuO+fPn45zj0ksv5Z133qGkpIT+/fvzyiuvAF6fSFlZWdxzzz3MmTOHXr16tW/NvoQ/fAReu0JN1PHpZ7qyWUQ61uzZs5k9ezYnn3wy48ePZ+XKlaxevZoxY8bw1ltvcfvtt/Puu++SlZXVIfVoT4ED3Wgv3lLKmPyO2fAi0km08Iu+IzjnuOOOO/jOd75zyLIFCxbw6quvcscdd3DBBRfw05/+NO71aE8ByM9Oo0d6RO0KItIhYrvOvvDCC5k5cyZ793pHKrZs2cL27dspLi4mPT2da665hltvvZWFCxce8tx40J4CXmPzmLws3VtBRDpEbNfZU6ZM4Wtf+xqnnXYaAJmZmTz55JOsWbOG2267jVAoRCQS4cEHHwRg+vTpTJkyhX79+sWlodmcc+3+oh2loKDAFRYWtstr/fL1lTzyzjqW3nkhqRE1Not0ZStWrODEE08MuowO0dRnNbMFzrmCptbX4SPf2PwsauscKz/Tlc0ikrgUCr4x+T0AWKI7sYlIAlMo+PpnpZKTkax2BZEEcSwfOm+to/mMCgWfmTE6L0s33BFJAKmpqezcubNLB4Nzjp07d5KamnpEz9PZRzHG5mfxwNwdVO6PkpasxmaRrio/P5+ioiJKSkqCLiWuUlNTyc/PP6LnKBRijMnLIlrnWL61jAmDsoMuR0TiJBKJMGTIkKDL6JTifvjIzMJm9g8ze9mf7mlmb5rZan+YHbPuHWa2xsxWmdmF8a6tsbF+Y/NStSuISILqiDaFm4EVMdMzgLedc8OBt/1pzGwkMA0YBUwGHjCzDj2G06d7Cr0yU9SuICIJK66hYGb5wMXA72NmXwY84Y8/AVweM/9p51y1c249sAaYGM/6GmvoRntLaUe+rYhIpxHvPYV7gX8BYm+A3Mc5txXAH/b25+cBm2PWK/LndagxeVms2b6Xiv21Hf3WIiKBi1somNklwHbn3ILWPqWJeYecL2Zm082s0MwK43HmwNj8LOocLC8ua/fXFhHp7OK5p3AGcKmZbQCeBs41syeBbWbWD8AfbvfXLwIGxDw/Hyhu/KLOuUeccwXOuYLc3Nx2L7r+ns1qVxCRRBS3UHDO3eGcy3fODcZrQP6bc+4a4CXgOn+164AX/fGXgGlmlmJmQ4DhwPx41dec3t1T6dM9RVc2i0hCCuI6hbuBZ83sBmAT8BUA59wyM3sWWA7UAjc556IB1MeYvB4sVh9IIpKAOiQUnHNzgbn++E7gC82s93Pg5x1RU0vG5mfx9spt7K2uJTNF1/eJSOJQ30dNGJOXhXOwTIeQRCTBKBSaMNpvbFa7gogkGoVCE3K7pdA/K1VnIIlIwlEoNGNMvu7ZLCKJR6HQjDF5WazfsY+yqpqgSxER6TAKhWaMUY+pIpKAFArNqL+yeYnaFUQkgSgUmtEzI5n87DQWa09BRBKIQqEFY/KydPhIRBKKQqEFY/Kz2Lizgj0VamwWkcSgUGjB2LwegC5iE5HEoVBoQUM32roTm4gkCIVCC7LSIwzsma52BRFJGAqFwxiTn6XuLkQkYSgUDmNsXhZFuyvZtW9/0KWIiMSdQuEwxuSrx1QRSRwKhcOo70Zb7QoikggUCofRPTXCkF4Zuj2niCQEhUIrjMnLUh9IIpIQFAqtMDY/i+I9VezYWx10KSIicaVQaAXdnlNEEoVCoRVG9e+OmbrRFpGuT6HQCt1SIwztlaGL2ESky1MotNLY/B4sUR9IItLFKRRaaXReFtvKqtleVhV0KSIicaNQaKWxurJZRBKAQqGVRvbrTshQu4KIdGkKhVbKSEliWO9M7SmISJemUDgCo/OyWLJlD865oEsREYkLhcIRGJuXRUl5NdvKdGWziHRNCoUjMCa/B4A6xxORLkuhcARG9utOOGRqVxCRLkuhcATSksMM752pM5BEpMtSKByhMXlZLFVjs4h0UXELBTNLNbP5ZvaJmS0zszv9+T3N7E0zW+0Ps2Oec4eZrTGzVWZ2Ybxqa4ux+Vns3Lef4j26sllEup547ilUA+c6504CxgGTzWwSMAN42zk3HHjbn8bMRgLTgFHAZOABMwvHsb6jUt/YvESNzSLSBcUtFJxnrz8Z8R8OuAx4wp//BHC5P34Z8LRzrto5tx5YA0yMV31Ha0TfbiSFTO0KItIlxbVNwczCZrYI2A686ZybB/Rxzm0F8Ie9/dXzgM0xTy/y5zV+zelmVmhmhSUlJfEsv0mpkTDH9+mmM5BEpEuKayg456LOuXFAPjDRzEa3sLo19RJNvOYjzrkC51xBbm5uO1V6ZMbm68pmEemaOuTsI+dcKTAXr61gm5n1A/CH2/3VioABMU/LB4o7or4jNSY/i9KKGop2VwZdiohIu4rn2Ue5ZtbDH08DzgNWAi8B1/mrXQe86I+/BEwzsxQzGwIMB+bHq762GDegBwBvLt8WbCEiIu0snnsK/YA5ZrYY+BivTeFl4G7gfDNbDZzvT+OcWwY8CywHXgducs5F41jfURvZrzunDunJA3PXsK+6NuhyRETajR3Lx8ULCgpcYWFhIO+9cNNurnjgA/7pvOO5+bzhgdQgInI0zGyBc66gqWW6ovkojR+YzYWj+vDIO2vZuVe9popI16BQaIPbLjyBypoo981ZE3QpIiLtQqHQBsN6d+MrEwbw5482sXlXRdDliIi0mUKhjW45fzhm8Js3Pw26FBGRNlMotFG/rDS+cfpgXli0hRVby4IuR0SkTRQK7eC75xxHt5QkfvXGqqBLERFpE4VCO+iRnsyN5xzH31ZuZ/76XUGXIyJy1BQK7eT604fQp3sKd7+2Qn0iicgxS6HQTtKSw9z8heNZuKlU3V+IyDGrVaFgZhlmFvLHjzezS80sEt/Sjj1TC/IZ2iuDX72ximid9hZE5NjT2j2Fd4BUM8vDu1va9cDj8SrqWJUUDnHrhSewevtenl9YFHQ5IiJHrLWhYM65CuAK4H+cc18CRsavrGPXlNF9OSk/i3vf/JSqmk7Zn5+ISLNaHQpmdhpwNfCKPy8pPiUd28yM2yePoHhPFX/6cGPQ5YiIHJHWhsItwB3AC865ZWY2FJgTt6qOcacP68VZw3tx/9w1lFXVBF2OiEirtSoUnHN/d85d6pz7hd/gvMM594M413ZMu33yCEoranjk7+uCLkVEpNVae/bRU2bW3cwy8G6Cs8rMbotvace20XlZfPGk/jz23nq2l1UFXY6ISKu09vDRSOdcGXA58CowELg2XkV1FT88/3hqonX87m+rgy5FRKRVWhsKEf+6hMuBF51zNYBOxD+Mwb0yuGriQJ6ev5kNO/YFXY6IyGG1NhQeBjYAGcA7ZjYIUJegrfD9LwwjEg7x69nqLE9EOr/WNjT/zjmX55y7yHk2Ap+Pc21dQu9uqXzrrCG8vHgrS4r2BF2OiEiLWtvQnGVm95hZof/4b7y9BmmF6WcPJTs9wi/fWBl0KSIiLWrt4aOZQDkw1X+UAX+IV1FdTbfUCDd9fhjvrt7B+2t2BF2OiEizWhsKxznn/s05t85/3AkMjWdhXc01kwaR1yONX7y+Ul1ri0in1dpQqDSzM+snzOwMoDI+JXVNqZEw/3T+8Swu2sOrSz4LuhwRkSa1NhRuBO43sw1mtgG4D/hO3Krqor50ch4n9OnGr2evoiZaF3Q5IiKHaO3ZR584504CxgJjnXMnA+fGtbIuKBwy/mXyCazfsY9nCzcHXY6IyCGO6M5rzrky/8pmgH+OQz1d3rkjenPK4Gx++9ZqKvbXBl2OiMhB2nI7Tmu3KhKImTFjygi2l1dz2/8u1h3aRKRTaUso6NvsKE0Y1JN/vfhEXlmylX/9vyU6G0lEOo0Wb5RjZuU0/eVvQFpcKkoQ3zprKKUVNdw3Zw090pO5ffKIoEsSEWk5FJxz3TqqkET0wwuOZ3fFfh6cu5YeaRG+87njgi5JRBKcbqkZIDPj3y8bzZ7KGu56bSU90iN89ZSBQZclIglMoRCwcMi4Z+o4yqtqueMvS8hKizB5dL+gyxKRBNWWhuYWmdkAM5tjZivMbJmZ3ezP72lmb5rZan+YHfOcO8xsjZmtMrML41VbZ5OcFOKhayZw8sBsfjBrEe+tVv9IIhKMuIUCUAv80Dl3IjAJuMnMRgIzgLedc8OBt/1p/GXTgFHAZOABMwvHsb5OJS05zMzrTmFobgbT/1TIPzbtDrokEUlAcQsF59xW59xCf7wcWAHkAZcBT/irPYF3Nzf8+U8756qdc+uBNcDEeNXXGWWlR/jjNyfSKzOF6x//mE+3lQddkogkmHjuKTQws8HAycA8oI9zbit4wQH09lfLA2L7fijy5zV+ren193UoKSmJa91B6N09lSdvOJXkcIhrH5vH5l0VQZckIgkk7qFgZpnA88AtMV1kNLlqE/MOuUbCOfeIc67AOVeQm5vbXmV2KgNz0vnjDROp3B/l2sfmUVJeHXRJIpIg4hoKZhbBC4Q/O+f+4s/eZmb9/OX9gO3+/CJgQMzT84HieNbXmY3o250/XD+RbWXVXDdzPmVVNUGXJCIJIJ5nHxnwGLDCOXdPzKKXgOv88euAF2PmTzOzFDMbAgwH5servmPBhEHZPHTtBFZvL+dbjxdSuT8adEki0sXFc0/hDOBa4FwzW+Q/LgLuBs43s9XA+f40zrllwLPAcuB14CbnXMJ/C37u+FzumTqOjzfu4qanFuo+DCISV3Ysd8ZWUFDgCgsLgy6jQ/x53kZ+/MJSLhvXn99MHUcopE5qReTomNkC51xBU8t0RfMx4upTB1FaUcOv3lhFj7QIP7t0FN4ROhGR9qNQOIb8v3OOo7RiP4++u54e6cn80/nHB12SiHQxCoVjiJnxo4tOpLSiht++vZrSiv3ccdGJpEYS5sJvEYkzhcIxxsy464oxdEuNMPP99by/die/nTaOUf2zgi5NRLqADrmiWdpXUjjET784kj9+cyJllTVcfv/7PPz3tdTp1p4i0kYKhWPY2cfn8votZ3PuiN7c9dpKrv79PIpLK4MuS0SOYQqFY1zPjGQeumYCv7xyLJ8UlTL53nf46ycJeyG4iLSRQqELMDOmnjKA124+i+N6Z/L9Wf/gn59ZpK4xROSIKRS6kEE5Gfzvd07jlvOG8+InxUy5910+3rAr6LJE5BiiUOhiksIhbjnveJ79zmmEQ8ZXH/6QX72xUt1jiEirKBS6qAmDsnn15rO4cnw+989Zy5UPfsC6kr1BlyUinZxCoQvLTEniV185iQevHs+mXRVc/Lv3eGreJo7l/q5EJL4UCglgyph+vH7z2UwYlM2PXljCt/+4gJ17deMeETmUQiFB9M1K5Y/fnMhPLhnJO5+WcOG97/LSJ8XaaxCRgygUEkgoZNxw5hBe+v4Z9Omewg9m/YOpD3/I0i17gi5NRDoJhUICGtG3Oy9970zuumIMa0v28cX73mPG84vZoUNKIglPoZCgwiHjqokDmXPrOXzzjCE8t6CIz/9qLr9/dx37a3X6qkiiUigkuKy0CD+5ZCSv33I24wdl85+vrGDyb99hzqrtQZcmIgFQKAgAw3pn8vj1pzDzGwU4B9f/4WO++fjHurZBJMEoFKSBmXHuiD68ccvZ/OiiEcxfv4sL732Hn7+yXP0oiSQIhYIcIjkpxPSzj2POrefwpZPz+P176zn313N55uNNumeDSBenUJBm5XZL4ZdfPokXbzqDQTkZ3P78Ei67/30K1cmeSJelUJDDGpvfg+duPI3fThtHSXk1X37oQ25++h9qbxDpgnSPZmkVM+OycXmcP7IPD85dy8PvrOPFRcWcc0Iu3zh9MGcPzyUUsqDLFJE2smO5m4OCggJXWFgYdBkJqaS8mqfmbeLJeRspKa9maG4G158+mCvG55ORot8aIp2ZmS1wzhU0uUyhIG2xv7aOV5YU84f3N7C4aA/dUpP4asEAvn7aYAbmpAddnog0QaEgceecY+GmUh7/YAOvLdlK1DnOO7EP158xmNOG5mCmQ0sinUVLoaD9fGkXZsaEQdlMGJTNZxedyJ8+2sBT8zbx5vJtjOjbjW+cPpjLT84jNRIOulQRaYH2FCRuqmqivLSomJnvr2flZ+X0SI9w1cSBXDtpEP17pAVdnkjC0uEjCZRzjnnrd/H4+xuYvfwzzIzJo/pyzaRBTBraU4eWRDqYDh9JoMyMSUNzmDQ0h827Knjyo43Mmr+JV5ZsZWivDKZNHMCV4/PJyUwJulSRhKc9BQlE5f4ory7Zyqz5myjcuJtI2LhgVF++NnEgpw3N0TUPInGkw0fSqa3eVs6s+Zt5fmEReyprGJSTzrRTBvLlCfnkdtPeg0h7CyQUzGwmcAmw3Tk32p/XE3gGGAxsAKY653b7y+4AbgCiwA+cc28c7j0UCl1LVU2U15d+xlPzNzF//S6SQsb5I/tw1cSBnDmsl/YeRNpJUKFwNrAX+GNMKPwS2OWcu9vMZgDZzrnbzWwkMAuYCPQH3gKOd85FW3oPhULXtWb7Xp75eBPPLShid0UNA3qmMe2UgXxlQj69u6cGXZ7IMS2ww0dmNhh4OSYUVgHnOOe2mlk/YK5z7gR/LwHn3F3+em8AP3POfdjS6ysUur7q2ihvLNvGrHmb+HDdTsIh47wTezNt4kDOOT5XZy6JHIXOdPZRH+fcVgA/GHr78/OAj2LWK/LnSYJLSQpz6Un9ufSk/qwr2cszH2/muQVFvLFsG9dMGsh/XDZawSDSjjpL19lN/a9uchfGzKabWaGZFZaUlMS5LOlMhuZmcsdFJ/LhHV/ghjOH8ORHm/j9u+uDLkukS+noUNjmHzbCH9bfHb4IGBCzXj5Q3NQLOOcecc4VOOcKcnNz41qsdE7JSSF+fNGJXDSmL//12gpeX7o16JJEuoyODoWXgOv88euAF2PmTzOzFDMbAgwH5ndwba3nHJR86g0lEKGQcc/UcYwb0INbnlnEos2lQZck0iXELRTMbBbwIXCCmRWZ2Q3A3cD5ZrYaON+fxjm3DHgWWA68Dtx0uDOPAuEcrHodHjkH7j8F3vq3oCtKaKmRMI9+vYDcbil864mP2byrIuiSRI55unitNZyDT9+AuXfB1kWQPRhyR8Cnr8Ol/wPjvx7/GqRZa7bv5YoH3qd391Sev/F0stIjQZck0qm1dPZRZ2lo7pycg1WveXsGs74KVaVw2f3wvUL46p/huHPh5X+C9e8EXWlCG9Y7k4evLWDjzn18988L2F9bF3RJIscshUJTGsLgczBrmh8GD3hhcPI1EI5AOAm+8jjkDINnroUda4KuOqGddlwOd18xlg/W7uRHLyzhWN4DFgmSQiHWIWGwJyYMrvbCIFZqFnztGQglwVNfgYpdwdQtAFw5IZ+bvzCc5xYUcd/fFNIiR0OhAF4YrHw1JgzKWg6DWNmDYdpTsGeLt8dQu7/DypZD3XLecK44OY//fvNTXly0JehyRI45iR0K9WHw8Nnw9FVHFgaxBp7qtTVsfA9evkWnqgbIzLjryjGcOqQnt/3vYuav196byJFIzFBoHAbV5XD5gzFhcBS9f4z9CnxuBiz6M7z3m/avWVotJSnMw9dOIL9nGtP/VMi6kr1BlyRyzEjMUFg399AwGPe1owuDWOfMgNFfhrfvhOUvHn59iZse6cn84RunEDLjm49/zK59Oqwn0hqJGQpDz4Gpf2q/MKhn5h1Gyp8If/kObFnYPq8rR2VQTgaPfr2A4j1VTP9jIVU1ne96SJHOJjFDwQxGXtp+YRArkuo1PGfmeo3We4ra/z2k1SYMyuY3U8dRuHE3tz23mLo6tfeItCQxQyHeMnPha89CTSU8NQ2qdUw7SBeP7ceMKSP46yfF/Pebq4IuR6RTUyjES+8T4St/gO3L4fkboE6HLoL0nbOHctXEAdw/Zy3Pfrw56HJEOi2FQjwNOw+m/MLrI2n2T4KuJqGZGf9+2WjOGt6LH72whPdW7wi6JJFOSaEQbxO/DafeCB/dD4Uzg64moUXCIR64ejzDemfy3ScX8NdPitX4LNKIQqEjXPhfMPwCeOVWWPu3oKtJaN1SI8z8xinkZCbz/Vn/YOLP3+Jf/28J/9i0W/0liaCusztOdTk8dqF3NtK33oTcE4KuKKFF6xzvr9nB8wuLeH3pZ1TX1nFcbgZXTsjnipPz6ZuVGnSJInHTUtfZCoWOVLoZHj0XImnw7b9BRq/DP8c52L/P65yvqtQf7vHm5Rd4fS9Jm5RV1fDq4q08v7CIjzfsxgzOHNaLL0/I54KRfUlLDgddoki7Uih0JkUL4PGLoO9YGHcVVJYe/IXfMB0zr662+dfrMwZOvARGXAx9RnvXYMhR27BjH39ZWMTzC7ewpbSSzJQkLhnbjysn5FMwKBvT9pUuQKHQ2Sx7AZ77Jjj/ZjDhZEjt4XXFneYPD5luNC+U5HXXsfIV2PQR4KDHIBhxiRcSA06FkH7hHq26OsdH63fy/IItvLZ0KxX7owzKSefK8flcMT6P/Oz0oEsUOWoKhc5o3w5vDyA1yzuc1BZ7t8OqV72AWDcXovshvRecMAVO/CIM+Zx3pbUclX3Vtby29DOeX1DEh+t2AjBpaE/OHNaLUf2zGNW/O7ndUrQXIccMhUIiqSqDNW/Bypfh09mwvxySM71rJkZcAsdf4AXRsSJaC2VFsHsD7FrvDXevh7Kt3mea9F1I7d5h5WzeVcEL/9jCi4u2sLZkX8P8XpnJjOyfxch+3RnVvzsj+3dnSE4GoZCCQjofhUKiqq2G9e/Cyr96XYXv2w6hCAw5C064CLr19abDSd7hqFDEu4dEKMkfNjEdCvu3I032p9vhrObqcv/LfsPBX/y71sOezQe3qYQikD3IO5S2pRDSsuH0H8DE6ZCS2fZajkBZVQ0ristYvrWMZcVlLC8uY/X2cmqi3v+p9OQwI/p2Y1T/LEb298Li+D7dSI3osJ4ES6EgUFcHRR97exArX4Zd69rndS3sBUQ4+UBYNAyTvcA5ZHkyWAjKt3pf/BWNri5O7QE9h0D2EO/sqp7+MHsIdO9/oK2k+B8w5y5Y/YZ3uOzMW6DgBkgO7nj//to6Vm8vbwiJ5VvLWFFcRnm1F2zhkDEsN5OR/bsztFcGA3qm+480cjN1CEo6hkJBDuac92u8uhzqarxDNHU1EK3xfpXXD1taFt1/YBj1l0f3x0zHjNc1tbwGuvU58GXf8MU/2Pv1fyQ2fwxzfg7r5kBmHzjzn2HCNzpNO0pdnaNodyXLivcctFfxWVnVQeulRcLkZ6cxsCEo0v3xNAZkp5OREodefSUhKRQkMWz8AOb8F2x4F7rnwVk/hJOvhaTkoCtrUlVNlKLdFWzeVcmmXRVs3lXhDXdXsnlXBXurDz4VOScjmfz6oPDDoz5A+mWlkhRWBwXSOgoFSSzr/u7tOWyeB1kD4XO3wUlXtf6e252Ac47Siho/JPyw2OWFxebdFWzZXUltzL0hwiEjr0caA3p6YZGfnX5QaGSnR3RoShooFCTxOAdr34a//RyKF3qHqD53O4yd2iWu36iN1vFZWRWbdlVQ5O9p1AfI5l0V7Nh78O1HM1OSGg5N1QdFfnYa/bLSyOuRRve0JIVGAlEoSOJyzuu6fM7P4bMlkDPcu5f2qCva58ypeHPOb9+JbeuJeu00DfOiB9qA6mohWktldTU79uyjpGwfO8r2satsH7vKKyndu4/SfZW4aC3J1BKhlmRqyAxH6ZlqZKc4slIgK1JHt0gdGUl1ZISipIaihOr2e2e01bcPWcg/eSBy8MkEoVaccBCKeM/3PuSBz9rkdDPrONdo2Nz8FoYu6m/jqHcxqfOHDdN1jaZjlh/u36016oPYDDBvaKED400OQ9543gQ45YbWvc8hb9t8KKjlSro2M+8ivuEXemddzb3Lu+nRO7+GvmMO/9yWuLoDX9INXxzRZub5813UOxOsYb1avzE/5ku9LnogANzRde2dBgzwH4cI0XT/yPth//4I+8sjVLsw+4lQ4ZLYQxL7ieDCESycQiiSQiQ5mdSkEOnhOtLCVSTbPi80Gk4oqG36xAOC+hHa3JdryNtzrB8/aNofhkKNpmPWP9x7tqilwKprYRne8rZe9NoMhYIkhlDIuy/3iEtg+Qvw4f3eKbrNOsyXl3P+l0M4Zuh/cYSSGi2LNDEvdOAakMaPsH89SChmebi59Y7kuZGDpxt+uSdDUgqEkkg2IxlIqolStqeK4tJKtpRWUtzw8OftrKS6tu7A5jXIy05jUM8MBuakM6hnOoNy0hmUk8HAnjFnTtVFDwRE7K/phgC2pqebXaelX9TGYYNdDqHDRyJyxJxzlJRXs3FXBRt27GPTrgo27qxg464KNu7cR2lFzUHr98pM8UMinUE9MxiUk06P9AipkbD/CJGaFDMeCZOSFFI7R5zo8JGItCszo3f3VHp3T+WUwT0PWb6nsoZNOyvYuGufFxY7veGHa3fyl4VbWv0+KUkh0pLDfmD4YREJk5oUIjkpRDhkJIXMHx6YTgob4VAoZpkRDteve2B+OGSEzQj569QPG88L24H16+dFQkZSOEQkbETCISLhEElhI9kfRsIhIqEQkSSvtkjYjomQUyiISLvLSoswJj+LMfmH9rNVf31GWVUtVfujVNVGqaqpo6omZujPq66JUlkTbbTMG+6rriVa56itc42GdUSjzcyvcw3dkAQhKWQN4REOGSEzDC9kzbzDcIZ5Q3+eN99bL2QG/vTnT8jlxxePbP8a2/0VRURakBoJM6x3t0BriPpBUecOhMZBD+eIRv1hU8vq6qiNegFTU1dHTW0dtXWOmmidNy9aR220jv1RR2207uD5dY79tXXUOeed+OSc13YcO+2gzoHDG3fO+dPechz0zVJDs4hIu6g/FCSH6nQnapvZZDNbZWZrzGxG0PWIiCSSThUKZhYG7gemACOBq8ys/Q+aiYhIkzpVKAATgTXOuXXOuf3A08BlAdckIpIwOlso5AGbY6aL/HkNzGy6mRWaWWFJSUmHFici0tV1tlBoquXnoPPHnHOPOOcKnHMFubm5HVSWiEhi6GyhUMTB3bXkA8UB1SIiknA6Wyh8DAw3syFmlgxMA14KuCYRkYTRqa5TcM7Vmtn3gDeAMDDTObcs4LJERBLGMd0hnpmVABvb8BK9gB2HXSs4qq9tVF/bqL626cz1DXLONdkoe0yHQluZWWFzPQV2BqqvbVRf26i+tuns9TWns7UpiIhIgBQKIiLSINFD4ZGgCzgM1dc2qq9tVF/bdPb6mpTQbQoiInKwRN9TEBGRGF0+FA7XFbd5fucvX2xm4zuwtgFmNsfMVpjZMjO7uYl1zjGzPWa2yH/8tKPq899/g5kt8d/7kBtiB7z9TojZLovMrMzMbmm0TodvPzObaWbbzWxpzLyeZvamma32h9nNPDfuXcc3U9+vzGyl/2/4gpn1aOa5Lf49xLG+n5nZlph/x4uaeW5Q2++ZmNo2mNmiZp4b9+3XZt7dfrrmA+8CuLXAUCAZ+AQY2Widi4DX8PpdmgTM68D6+gHj/fFuwKdN1HcO8HKA23AD0KuF5YFtvyb+rT/DO/860O0HnA2MB5bGzPslMMMfnwH8opnP0OLfaxzruwBI8sd/0VR9rfl7iGN9PwNubcXfQCDbr9Hy/wZ+GtT2a+ujq+8ptKYr7suAPzrPR0APM+vXEcU557Y65xb64+XAChr1CnsMCGz7NfIFYK1zri0XM7YL59w7wK5Gsy8DnvDHnwAub+KpHdJ1fFP1OedmO+dq/cmP8PodC0Qz2681Att+9czMgKnArPZ+347S1UPhsF1xt3KduDOzwcDJwLwmFp9mZp+Y2WtmNqpjK8MBs81sgZlNb2J5p9h+eP1kNfcfMcjtV6+Pc24reD8GgN5NrNNZtuU38fb+mnK4v4d4+p5/eGtmM4ffOsP2OwvY5pxb3czyILdfq3T1UDhsV9ytXCeuzCwTeB64xTlX1mjxQrxDIicB/wP8X0fWBpzhnBuPdze8m8zs7EbLO8P2SwYuBf63icVBb78j0Rm25Y+BWuDPzaxyuL+HeHkQOA4YB2zFO0TTWODbD7iKlvcSgtp+rdbVQ6E1XXEH2l23mUXwAuHPzrm/NF7unCtzzu31x18FImbWq6Pqc84V+8PtwAt4u+ixOkN351OAhc65bY0XBL39YmyrP6zmD7c3sU7Qf4vXAZcAVzv/AHhjrfh7iAvn3DbnXNQ5Vwc82sz7Br39koArgGeaWyeo7XckunootKYr7peAr/tn0UwC9tTv5sebf/zxMWCFc+6eZtbp66+HmU3E+zfb2UH1ZZhZt/pxvMbIpY1WC2z7xWj211mQ26+Rl4Dr/PHrgBebWCewruPNbDJwO3Cpc66imXVa8/cQr/pi26m+1Mz7Bt31/nnASudcUVMLg9x+RyTolu54P/DOjvkU76yEH/vzbgRu9McNuN9fvgQo6MDazsTbvV0MLPIfFzWq73vAMrwzKT4CTu/A+ob67/uJX0On2n7++6fjfclnxcwLdPvhBdRWoAbv1+sNQA7wNrDaH/b01+0PvNrS32sH1bcG73h8/d/hQ43ra+7voYPq+5P/97UY74u+X2fafv78x+v/7mLW7fDt19aHrmgWEZEGXf3wkYiIHAGFgoiINFAoiIhIA4WCiIg0UCiIiEgDhYJIE8wsagf3wNpuPW6a2eDYHjZFOpOkoAsQ6aQqnXPjgi5CpKNpT0HkCPj94f/CzOb7j2H+/EFm9rbfYdvbZjbQn9/Hvz/BJ/7jdP+lwmb2qHn30ZhtZmn++j8ws+X+6zwd0MeUBKZQEGlaWqPDR1+NWVbmnJsI3Afc68+7D68L8bF4ncn9zp//O+DvzuuQbzzelawAw4H7nXOjgFLgSn/+DOBk/3VujM9HE2mermgWaYKZ7XXOZTYxfwNwrnNund+Z4WfOuRwz24HX9UKNP3+rc66XmZUA+c656pjXGAy86Zwb7k/fDkScc/9pZq8De/F6c/0/53fmJ9JRtKcgcuRcM+PNrdOU6pjxKAfa9y7G60tqArDA73lTpMMoFESO3Fdjhh/64x/g9coJcDXwnj/+NvBdADMLm1n35l7UzELAAOfcHOBfgB7AIXsrIvGkXyEiTUuzg2++/rpzrv601BQzm4f3o+oqf94PgJlmdhtQAlzvz78ZeMTMbsDbI/guXg+bTQkDT5pZFl7vs79xzpW20+cRaRW1KYgcAb9NocA5tyPoWkTiQYePRESkgfYURESkgfYURESkgUJBREQaKBRERKSBQkFERBooFEREpIFCQUREGvx/Fk5OEXbA26wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting loss convergence\n",
    "\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(test_loss, label='test')\n",
    "plt.suptitle(\"Loss Convergence\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting accuracy convergence\n",
    "\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(test_acc, label='test')\n",
    "plt.suptitle(\"Accuracy Improvement\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
